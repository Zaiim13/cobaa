{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYIolSAGAYk2",
        "outputId": "45b4c97a-661f-4bc5-ce0c-91380c389edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.14)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: replicate in /usr/local/lib/python3.11/dist-packages (1.0.7)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from replicate) (25.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.11/dist-packages (from replicate) (2.11.7)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (4.14.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Replicate\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "\n",
        "# Set the API token\n",
        "api_token = userdata.get('REPLICATE_API_TOKEN')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.2-8b-instruct\"\n",
        "output = Replicate(\n",
        "    model=model,\n",
        "    replicate_api_token=api_token,\n",
        ")\n",
        "\n",
        "# Load data from CSV file in sample_data folder\n",
        "def load_data_from_csv(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        if 'slang' in df.columns:\n",
        "            return df['slang'].tolist()\n",
        "        elif 'formal' in df.columns:\n",
        "            return df['formal'].tolist()\n",
        "        else:\n",
        "            # Jika tidak ada kolom yang sesuai, ambil kolom pertama\n",
        "            return df.iloc[:, 0].tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file: {e}\")\n",
        "        return []\n",
        "\n",
        "# Path to your file in sample_data folder\n",
        "file_path = '/content/sample_data/slang-indo.csv'\n",
        "data = load_data_from_csv(file_path)\n",
        "\n",
        "# Check if data were loaded\n",
        "if not data:\n",
        "    print(\"No data found or error loading file!\")\n",
        "else:\n",
        "    print(f\"Loaded {len(data)} data from file\")\n",
        "\n",
        "    # Refine the prompt to include reviews\n",
        "    ini = \"\\n\".join([f\"Review {i+1}: {review}\" for i, review in enumerate(data)])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The two parallel columns have the same meaning, but the form of language is different. The slang column is filled with the slang language / Everyday language that people use on the internet, while the formal column is filled with the formal language form of the slang columns so that it is easier to understand. Please deduce what 10 patterns are formed from formal language to slang language:\n",
        "    {ini}\n",
        "    \"\"\"\n",
        "\n",
        "    # Invoke the model with the example prompt\n",
        "    response = output.invoke(prompt)\n",
        "\n",
        "    # Print the response\n",
        "    print(\"\\nGranite Model Response:\\n\")\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yx6j6HlAp7l",
        "outputId": "e1f1fcba-5b39-4efa-c07e-d480a235eb6f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 4412 data from file\n",
            "\n",
            "Granite Model Response:\n",
            "\n",
            "Here are 10 patterns formed from formal language to slang language:\n",
            "\n",
            "1. Review 1: wow -> yaa\n",
            "2. Review 2: aminn -> amin\n",
            "3. Review 3: met -> ke\n",
            "4. Review 4: netaas -> nta\n",
            "5. Review 5: keberpa -> kebpa\n",
            "6. Review 6: eeeehhhh -> ehh\n",
            "7. Review 7: kata2nyaaa -> kata2nya\n",
            "8. Review 8: hallo -> hai\n",
            "9. Review 9: kaka -> kakak\n",
            "10. Review 10: ka -> kau\n",
            "\n",
            "These patterns show a general trend of abbreviating words, omitting vowels, or using common internet slang abbreviations. For example, \"wow\" becomes \"yaa\", \"aminn\" becomes \"amin\", and \"hallo\" becomes \"hai\". The use of \"kak\" for \"kaka\" and \"ka\" for \"kau\" also reflects the informal, conversational tone of internet slang.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define refined prompt\n",
        "refined_prompt = f\"\"\"\n",
        "Complete the task in 2 steps.\n",
        "Step 1: Please classify the following data based on these patterns; Adding consonants and vowels (baik -> baaiikkk), removing vowels (yang -> yng), abbreviating with an abstract pattern (begitu -> gtu), removing a letter (skali - > sekali), adding numbers to repeat words (rata-rata -> rata2). Similar patterns can be put together. Please do not translate the data when displayed on the output\n",
        "Step 2: count the total of the each patterns variabels above\n",
        "{ini}\n",
        "\"\"\"\n",
        "# Invoke the model with refined prompt\n",
        "response = output.invoke(refined_prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Refined Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efYB2HkfMTBE",
        "outputId": "abba2eae-5793-454d-a192-8ce77a2250bb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Refined Response:\n",
            "\n",
            "Step 1: Classification of data based on the given patterns:\n",
            "\n",
            "1. Adding consonants and vowels: 1 (baik -> baaiikkk)\n",
            "2. Removing vowels: 1 (yang -> yng)\n",
            "3. Abbreviating with an abstract pattern: 2 (begitu -> gtu, slalu -> slu)\n",
            "4. Removing a letter: 1 (skali -> sekali)\n",
            "5. Adding numbers to repeat words: 1 (rata-rata -> rata2)\n",
            "\n",
            "Step 2: Count of each pattern variables:\n",
            "\n",
            "1. Adding consonants and vowels: 1\n",
            "2. Removing vowels: 1\n",
            "3. Abbreviating with an abstract pattern: 2\n",
            "4. Removing a letter: 1\n",
            "5. Adding numbers to repeat words: 1\n",
            "\n",
            "The provided data does not contain instances of all the mentioned patterns. Therefore, the counts are as follows:\n",
            "\n",
            "- Adding consonants and vowels: 1 instance (baik -> baaiikkk)\n",
            "- Removing vowels: 1 instance (yang -> yng)\n",
            "- Abbreviating with an abstract pattern: 2 instances (begitu -> gtu, slalu -> slu)\n",
            "- Removing a letter: 1 instance (skali -> sekali)\n",
            "- Adding numbers to repeat words: 1 instance (rata-rata -> rata2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    prompt = f\"\"\"\n",
        "    The two parallel columns have the same meaning, but the form of language is different. The slang column is filled with the slang language / Everyday language that people use on the internet, while the formal column is filled with the formal language form of the slang columns so that it is easier to understand.\n",
        "    please conclude 3 Most repeated formal columns written based on the data and calculate the total number of each. Please do not translate the data when displayed on the output\n",
        "    {ini}\n",
        "    \"\"\"\n",
        "\n",
        "    # Invoke the model with the example prompt\n",
        "    response = output.invoke(prompt)\n",
        "\n",
        "    # Print the response\n",
        "    print(\"\\nGranite Model Response:\\n\")\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq6mzSfHd2rF",
        "outputId": "293e9909-9864-417c-975c-636fd56df1d9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Granite Model Response:\n",
            "\n",
            "The most repeated formal columns are:\n",
            "\n",
            "1. \"amin\" - 11 occurrences\n",
            "2. \"slm\" - 9 occurrences\n",
            "3. \"tq\" - 7 occurrences\n",
            "\n",
            "The total number of each is as follows:\n",
            "\n",
            "1. \"amin\": 11\n",
            "2. \"slm\": 9\n",
            "3. \"tq\": 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    ref_prompt = f\"\"\"\n",
        "    please conclude 3 Most common words on the formal columns based on the data. Please do not translate the data when displayed on the output. and then calculate the total number of each\n",
        "    {ini}\n",
        "    \"\"\"\n",
        "\n",
        "    # Invoke the model with the example prompt\n",
        "    response = output.invoke(ref_prompt)\n",
        "\n",
        "    # Print the response\n",
        "    print(\"\\nGranite Model Response:\\n\")\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r1R3NTMjxTU",
        "outputId": "7402a35a-d4d8-4442-a536-621cda87f523"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Granite Model Response:\n",
            "\n",
            "Based on the provided data, the three most common words are:\n",
            "\n",
            "1. amiiinn (11 occurrences)\n",
            "2. aminnn (9 occurrences)\n",
            "3. yaaa (8 occurrences)\n",
            "\n",
            "The total number of each word is as follows:\n",
            "\n",
            "1. amiiinn: 11\n",
            "2. aminnn: 9\n",
            "3. yaaa: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    ref_prompt = f\"\"\"\n",
        "    please conclude 3 less common words on the formal columns based on the data. Please do not translate the data when displayed on the output. and then calculate the total number of each\n",
        "    {ini}\n",
        "    \"\"\"\n",
        "\n",
        "    # Invoke the model with the example prompt\n",
        "    response = output.invoke(ref_prompt)\n",
        "\n",
        "    # Print the response\n",
        "    print(\"\\nGranite Model Response:\\n\")\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0yYkRWXoNz3",
        "outputId": "d8901e69-849a-488a-f4de-befe147446dd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Granite Model Response:\n",
            "\n",
            "Three less common words from the formal columns are:\n",
            "\n",
            "1. \"subhanallah\" (188, 189, 190)\n",
            "2. \"astagfirullah\" (186, 187, 188)\n",
            "3. \"mashaallah\" (191, 192, 193)\n",
            "\n",
            "These words are considered less common in formal writing due to their religious connotations and are more frequently used in informal or colloquial contexts. Their usage count in the data is as follows:\n",
            "\n",
            "- subhanallah: 3\n",
            "- astagfirullah: 3\n",
            "- mashaallah: 3\n"
          ]
        }
      ]
    }
  ]
}